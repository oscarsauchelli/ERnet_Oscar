{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "255\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=512x512 at 0x7F896C266E90>,\n",
       " array([[1.01524535e-09, 1.01529876e-09, 1.01546009e-09, ...,\n",
       "         1.01572843e-09, 1.01546018e-09, 1.01529875e-09],\n",
       "        [1.01529870e-09, 1.01535265e-09, 1.01551347e-09, ...,\n",
       "         1.01578220e-09, 1.01551338e-09, 1.01535267e-09],\n",
       "        [1.01546010e-09, 1.01551352e-09, 1.01567488e-09, ...,\n",
       "         1.01594328e-09, 1.01567497e-09, 1.01551351e-09],\n",
       "        ...,\n",
       "        [1.01572830e-09, 1.01578228e-09, 1.01594316e-09, ...,\n",
       "         1.01621201e-09, 1.01594307e-09, 1.01578229e-09],\n",
       "        [1.01546010e-09, 1.01551352e-09, 1.01567488e-09, ...,\n",
       "         1.01594328e-09, 1.01567497e-09, 1.01551351e-09],\n",
       "        [1.01529870e-09, 1.01535265e-09, 1.01551347e-09, ...,\n",
       "         1.01578220e-09, 1.01551338e-09, 1.01535267e-09]]))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from extraOperations import PsfOtf\n",
    "\n",
    "PsfOtf(512,0.8)\n"
   ]
  },
  {
   "source": [
    "# ERNet: CNN segmentation model for "
   ],
   "cell_type": "markdown",
   "metadata": {
    "id": "oQ-EedgSKYpE"
   }
  },
  {
   "source": [
    "# Packages"
   ],
   "cell_type": "markdown",
   "metadata": {
    "id": "1QU9SevFKYpK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6116,
     "status": "ok",
     "timestamp": 1612179177665,
     "user": {
      "displayName": "Oscar Sauchelli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWXu72zDm8qVoGEWdJGObsjbaAzqjYsfbkqLY2WA=s64",
      "userId": "08794093453290445854"
     },
     "user_tz": -60
    },
    "id": "NjFdNpfmKYpL"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from models import GetModel\n",
    "from datahandler import GetDataloaders\n",
    "\n",
    "from plotting import testAndMakeCombinedPlots\n"
   ]
  },
  {
   "source": [
    "# Options"
   ],
   "cell_type": "markdown",
   "metadata": {
    "id": "YdbPDrodKYpa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 604,
     "status": "ok",
     "timestamp": 1612179296061,
     "user": {
      "displayName": "Oscar Sauchelli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWXu72zDm8qVoGEWdJGObsjbaAzqjYsfbkqLY2WA=s64",
      "userId": "08794093453290445854"
     },
     "user_tz": -60
    },
    "id": "GYw0crCEKYpb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "options loaded\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "opt = argparse.Namespace()\n",
    "\n",
    "opt.root = 'trainingdata/testpartitioned_128'\n",
    "opt.out = 'trained_models/ERNet_rcan-rg5-t'\n",
    "opt.imageSize = 128\n",
    "opt.model = 'rcan'\n",
    "opt.nch_in = 3\n",
    "opt.nch_out = 3 \n",
    "opt.ntrain =  100\n",
    "opt.ntest = 10\n",
    "opt.batchSize = 3 # reduce if not enough VRAM \n",
    "opt.batchSize_test = 1\n",
    "opt.n_resgroups = 15\n",
    "opt.n_resblocks = 5\n",
    "opt.n_feats = 48\n",
    "opt.narch = 0\n",
    "opt.reduction = 16\n",
    "opt.lr = 0.0001 \n",
    "opt.workers = 4\n",
    "opt.scheduler = 10,0.5 \n",
    "opt.nepoch = 1\n",
    "opt.cpu = False\n",
    "opt.multigpu = False\n",
    "opt.log = False\n",
    "opt.test = False\n",
    "opt.saveinterval = 10\n",
    "opt.testinterval = 1\n",
    "opt.plotinterval = 33\n",
    "opt.weights = ''\n",
    "opt.dataset = 'pickledataset'\n",
    "opt.scheduler = ''\n",
    "opt.task = 'segment'\n",
    "print('options loaded')"
   ]
  },
  {
   "source": [
    "# Train function"
   ],
   "cell_type": "markdown",
   "metadata": {
    "id": "8bvbYDZ_KYpS"
   }
  },
  {
   "source": [
    "def train(dataloader, validloader, net, opt, nepoch=10):\n",
    "    \n",
    "    start_epoch = 0\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=opt.lr)\n",
    "\n",
    "    useGPU = torch.cuda.is_available() and not opt.cpu\n",
    "    \n",
    "    if useGPU:\n",
    "        loss_function.cuda()\n",
    "\n",
    "\n",
    "    if len(opt.weights) > 0: # load previous weights?\n",
    "        checkpoint = torch.load(opt.weights)\n",
    "        print('loading checkpoint',opt.weights)\n",
    "        if opt.undomulti:\n",
    "            checkpoint['state_dict'] = remove_dataparallel_wrapper(checkpoint['state_dict'])\n",
    "        else:\n",
    "            net.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            start_epoch = checkpoint['epoch']\n",
    "\n",
    "\n",
    "    if len(opt.scheduler) > 0:\n",
    "        stepsize, gamma = int(opt.scheduler.split(',')[0]), float(opt.scheduler.split(',')[1])\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, stepsize, gamma=gamma, last_epoch=start_epoch-1)\n",
    "\n",
    "    count = 0\n",
    "    opt.t0 = time.perf_counter()\n",
    "\n",
    "    for epoch in range(start_epoch, nepoch):\n",
    "        mean_loss = 0\n",
    "\n",
    "        for i, bat in enumerate(dataloader):\n",
    "            lr, hr = bat[0], bat[1]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if useGPU:\n",
    "                sr = net(lr.cuda())\n",
    "                hr = hr.cuda()\n",
    "            else:\n",
    "                sr = net(lr)\n",
    "        \n",
    "\n",
    "            loss = loss_function(sr, hr)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            ######### Status and display #########\n",
    "            mean_loss += loss.data.item()\n",
    "            print('\\r[%d/%d][%d/%d] Loss: %0.6f' % (epoch+1,nepoch,i+1,len(dataloader),loss.data.item()),end='')\n",
    "            \n",
    "            count += 1\n",
    "            if opt.log and count*opt.batchSize // 1000 > 0:\n",
    "                t1 = time.perf_counter() - opt.t0\n",
    "                mem = torch.cuda.memory_allocated()\n",
    "                print(epoch, count*opt.batchSize, t1, mem, mean_loss / count, file=opt.train_stats)\n",
    "                opt.train_stats.flush()\n",
    "                count = 0\n",
    "\n",
    "\n",
    "\n",
    "        # ---------------- Scheduler -----------------\n",
    "        if len(opt.scheduler) > 0:\n",
    "            scheduler.step()\n",
    "            for param_group in optimizer.param_groups:\n",
    "                print('\\nLearning rate',param_group['lr'])\n",
    "                break        \n",
    "\n",
    "\n",
    "        # ---------------- Printing -----------------\n",
    "        print('\\nEpoch %d done, %0.6f' % (epoch,(mean_loss / len(dataloader))))\n",
    "        print('\\nEpoch %d done, %0.6f' % (epoch,(mean_loss / len(dataloader))),file=opt.fid)\n",
    "        opt.fid.flush()\n",
    "        if opt.log:\n",
    "            opt.writer.add_scalar('data/mean_loss', mean_loss / len(dataloader), epoch)\n",
    "\n",
    "\n",
    "        # ---------------- TEST -----------------\n",
    "        if (epoch + 1) % opt.testinterval == 0:\n",
    "            testAndMakeCombinedPlots(net,validloader,opt,epoch)\n",
    "            # if opt.scheduler:\n",
    "                # scheduler.step(mean_loss / len(dataloader))\n",
    "\n",
    "        if (epoch + 1) % opt.saveinterval == 0:\n",
    "            torch.save(net.state_dict(), opt.out + '/prelim.pth')\n",
    "            checkpoint = {'epoch': epoch + 1,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict() }\n",
    "            torch.save(checkpoint, opt.out + '/prelim.pth')\n",
    "    \n",
    "    checkpoint = {'epoch': nepoch,\n",
    "    'state_dict': net.state_dict(),\n",
    "    'optimizer' : optimizer.state_dict() }\n",
    "    torch.save(checkpoint, opt.out + '/final.pth')\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 802,
     "status": "ok",
     "timestamp": 1612180049456,
     "user": {
      "displayName": "Oscar Sauchelli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWXu72zDm8qVoGEWdJGObsjbaAzqjYsfbkqLY2WA=s64",
      "userId": "08794093453290445854"
     },
     "user_tz": -60
    },
    "id": "-M2cDwhAKYpT"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKrfNwWgLc-a"
   },
   "source": [
    "# Build Training Data"
   ]
  },
  {
   "source": [
    "%run buildTrainingData.py\n",
    "# Doesn't work on google colab\n",
    "# no time to figure out\n",
    "# build training data on spyder"
   ],
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 44020,
     "status": "error",
     "timestamp": 1612179223910,
     "user": {
      "displayName": "Oscar Sauchelli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWXu72zDm8qVoGEWdJGObsjbaAzqjYsfbkqLY2WA=s64",
      "userId": "08794093453290445854"
     },
     "user_tz": -60
    },
    "id": "YRZSn9eAkED0",
    "outputId": "26ae5ef2-6608-45b4-ec83-cd01eba61ef5",
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSECFaK-KYpf"
   },
   "source": [
    "# Start training"
   ]
  },
  {
   "source": [
    "try:\n",
    "    os.makedirs(opt.out)\n",
    "except IOError:\n",
    "    pass\n",
    "\n",
    "opt.fid = open(opt.out + '/log.txt','w')\n",
    "print(opt)\n",
    "print(opt,'\\n',file=opt.fid)\n",
    "\n",
    "dataloader, validloader = GetDataloaders(opt)        \n",
    "net = GetModel(opt)  \n",
    "\n",
    "if opt.log:\n",
    "    opt.train_stats = open(opt.out.replace('\\\\','/') + '/train_stats.csv','w')\n",
    "    opt.test_stats = open(opt.out.replace('\\\\','/') + '/test_stats.csv','w')\n",
    "    print('iter,nsample,time,memory,meanloss',file=opt.train_stats)\n",
    "    print('iter,time,memory,psnr,ssim',file=opt.test_stats)\n",
    "\n",
    "import time\n",
    "t0 = time.perf_counter()\n",
    "if not opt.test:\n",
    "    train(dataloader, validloader, net, opt, nepoch=opt.nepoch)\n",
    "else:\n",
    "    if len(opt.weights) > 0: # load previous weights?\n",
    "        checkpoint = torch.load(opt.weights)\n",
    "        print('loading checkpoint',opt.weights)\n",
    "        if opt.undomulti:\n",
    "            checkpoint['state_dict'] = remove_dataparallel_wrapper(checkpoint['state_dict'])\n",
    "        net.load_state_dict(checkpoint['state_dict'])\n",
    "        print('time: ',time.perf_counter()-t0)\n",
    "   # testAndMakeCombinedPlots(net,validloader,opt)\n",
    "print('time: ',time.perf_counter()-t0)"
   ],
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "executionInfo": {
     "elapsed": 6176,
     "status": "error",
     "timestamp": 1612180204413,
     "user": {
      "displayName": "Oscar Sauchelli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWXu72zDm8qVoGEWdJGObsjbaAzqjYsfbkqLY2WA=s64",
      "userId": "08794093453290445854"
     },
     "user_tz": -60
    },
    "id": "CWVSoPbEKYpg",
    "outputId": "842c8ae2-65f1-4f4d-b62f-6a1dd77af164",
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Tmux training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "!python evaluate.py --root Model_Evaluation_Edward_Tiffs/01_Network_15.04.2021_20groups_10blocks/Input_PNGs/Ting   --weights  trained_models/Previous_Models/Network_15_04_2021_20groups_10blocks --imageSize 270      --out Model_Evaluation_Edward_Tiffs/01_Network_15.04.2021_20groups_10blocks/Output_PNGs    --model rcan --nch_in 3 --nch_out 3 --n_resgroups 20  --n_resblocks 10 --workers 0"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Ed's Tiff Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "filenames = [\"athesim mito 1\",\"athesim mito 3\",\"Meng ER 1\",\"Meng ER-3\",\"Meng mito 2\",\"microtubules 2\"]\n",
    "\n",
    "def Unstack():\n",
    "#image dimensions of tif to numpy array are: z,y,x\n",
    "#image dimensions of PNG to numpy array are: y,x, z with z being channels usually\n",
    "    network1 = \"01_Network_15.04.2021_20groups_10blocks\"\n",
    "    network2 = \"02_Network_13.04.2021_15groups_5blocks\"\n",
    "    for j in range(0,6):\n",
    "        dirTif = \"Model_Evaluation_Edward_Tiffs/\"   + network2 +  \"/Input_Tiffs/\" + filenames[j]  + \".tif\"\n",
    "        imTif = io.imread(dirTif)\n",
    "        imTif = np.array(imTif)\n",
    "        if j == 3:\n",
    "            imTif = (imTif/256).astype(np.uint8)\n",
    "            imTif = imTif.astype(np.uint8)\n",
    "        (slides ,height, width) = imTif.shape \n",
    "\n",
    "        for i in range(0,slides) : #TIFslides is not included, only goes up to TIFslides - 1\n",
    "             slide = np.copy(imTif[i,:,:])\n",
    "             slide = np.expand_dims(slide, axis = 2)\n",
    "             slide = np.concatenate((slide,slide,slide), axis=2)\n",
    "             slide = slide.astype(np.uint8)\n",
    "             slide = Image.fromarray(slide) \n",
    "             slide_name = \"Model_Evaluation_Edward_Tiffs/\"  + network2 + \"/Input_PNGs/\" + filenames[j] + \"_slide_\" + str(i+1) + \".png\"\n",
    "             slide.save(slide_name)\n",
    "Unstack()"
   ]
  },
  {
   "source": [
    "!python evaluate.py --root  Model_Evaluation_Edward_Tiffs/02_Network_13.04.2021_15groups_5blocks/Input_PNGs   --weights  trained_models/Previous_Models/Network_13_04_2021_15groups_5blocks --imageSize 270             --out Model_Evaluation_Edward_Tiffs/02_Network_13.04.2021_15groups_5blocks/Output_PNGs    --model rcan --nch_in 3 --nch_out 3 --n_resgroups 15  --n_resblocks 5 --workers 0"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "filenames = [\"athesim mito 1\",\"athesim mito 3\",\"Meng ER 1\",\"Meng ER-3\",\"Meng mito 2\",\"microtubules 2\"]\n",
    "\n",
    "def Restack():\n",
    "    network1 = \"01_Network_15.04.2021_20groups_10blocks\"\n",
    "    network2 = \"02_Network_13.04.2021_15groups_5blocks\"\n",
    "    for j in range(0,6):\n",
    "        dirTif = \"Model_Evaluation_Edward_Tiffs/\"   + network2 +  \"/Input_Tiffs/\" + filenames[j]  + \".tif\"\n",
    "        imTif = io.imread(dirTif)\n",
    "        imTif = np.array(imTif)\n",
    "        if j == 3:\n",
    "            imTif = (imTif/256).astype(np.uint8)\n",
    "            imTif = imTif.astype(np.uint8)\n",
    "        (slides ,height, width) = imTif.shape \n",
    "        newTif = imTif\n",
    "        for i in range(0,slides) : #TIFslides is not included, only goes up to TIFslides - 1\n",
    "             dirPNG = \"Model_Evaluation_Edward_Tiffs/\" + network2 + \"/Output_PNGs/\" + filenames[j] +  \"_slide_\" + str(i+1) + \"_out.png\"\n",
    "             slide = io.imread(dirPNG)\n",
    "             slide = np.array(slide)\n",
    "             slide = np.mean(slide,axis = 2)\n",
    "             newTif[i,:,:] = slide   \n",
    "        newTif_dir =  \"Model_Evaluation_Edward_Tiffs/\"   + network2 +  \"/Output_Tiffs/\" + filenames[j]  + \"_out.tif\"\n",
    "        io.imsave(newTif_dir, newTif)\n",
    "Restack()\n",
    " "
   ]
  },
  {
   "source": [
    "# Evaluate the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "import parser\n",
    "import os\n",
    "import scipy.ndimage as ndimage\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage import io\n",
    "from extraOperations import PSFnoise\n",
    "\n",
    "number_of_raw_inputs = 5\n",
    "raw_inputs = ['trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Processed_Input_A/001.png', 'trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Processed_Input_A/002.png','trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Processed_Input_B/003.png','trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Processed_Input_B/004.png','trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Processed_Input_B/005.png']\n",
    "\n",
    "    \n",
    "for i in range (0,number_of_raw_inputs,1):   # list indexing starts at 0\n",
    "    image = Image.open(raw_inputs[i])\n",
    "    image = np.array(image)\n",
    "    image = np.mean(image,axis = 2)\n",
    "    image = image.astype(np.uint8)\n",
    "    image = Image.fromarray(image)\n",
    "    dir = 'trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Model_evaluation_ouput' + '/00' + str(i) + \"_out.png\"\n",
    "    image.save(dir)\n",
    "\n",
    "\n",
    "#    if (i < 2):\n",
    " #       image = np.expand_dims(image, axis = 2)\n",
    "  #      image = np.concatenate((image,image,image), axis=2)\n",
    "   #     image = Image.fromarray(image)\n",
    "    #    image_name = \"Model_Evaluation_Input/Processed_Input_A/00\" + str(i+1) +  \".png\"\n",
    "#        image.save(image_name)\n",
    " #   else:\n",
    "  #      image = Image.fromarray(image)\n",
    "   #     image_name = \"Model_Evaluation_Input/Processed_Input_B/00\" + str(i+1) +  \".png\"\n",
    "    #    image.save(image_name)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(batchSize=16, batchSize_test=1, cpu=False, dataset='imagedataset', fid=<_io.TextIOWrapper name='trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Model_evaluation_ouput/log.txt' mode='w' encoding='UTF-8'>, imageSize=750, log=False, lr=0.0001, model='rcan', multigpu=False, n_feats=64, n_resblocks=8, n_resgroups=18, narch=0, nch_in=1, nch_out=1, nepoch=10, ntest=10, ntrain=0, out='trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Model_evaluation_ouput', plotinterval=1, reduction=16, root='trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Processed_Input_B', saveinterval=10, scheduler='', test=False, testinterval=1, undomulti=False, weights='trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/final.pth', workers=6)\n",
      "loading checkpoint trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/final.pth\n",
      "0.0 1.0 (1040, 1392)\n",
      "[4/4][1/3], shape is 750x750 - trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Processed_Input_B/002_out.png 0\n",
      "saved\n",
      "0.0 1.0 (1040, 1392)\n",
      "[4/4][2/3], shape is 750x750 - trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Processed_Input_B/003_out.png 1\n",
      "saved\n",
      "0.0 1.0 (1040, 1392)\n",
      "[4/4][3/3], shape is 750x750 - trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Processed_Input_B/004_out.png 2\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "!python evaluate.py --root trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Processed_Input_B --weights trained_models/Previous_Models/Network_Bovey_Widefield_Restoration --imageSize 750 --out trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/Model_evaluation_ouput --model rcan --nch_in 1 --nch_out 1 --n_resgroups 18 --n_resblocks 8"
   ]
  },
  {
   "source": [
    "# Evaluating Triplets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from buildTrainingData import noisy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "filename = \"Model_Evaluation_Triplets/0002.png\"\n",
    "img = Image.open(filename)\n",
    "img = np.array(img.mean)\n",
    "height = img.shape[0]\n",
    "img = img[700:1212,700:1212,:]\n",
    "io.imsave(filename.replace(\".png\",\"_gt.png\"), img)\n",
    "\n",
    "#Copy of Poisson noise code which is actually PSF noise, followed by Gaussian noise\n",
    "poisson_param = 100 \n",
    "img = img.astype(float) \n",
    "img = noisy(\"poisson\",img,[0,poisson_param])\n",
    "gauss_param = abs(0.002*np.random.randn()+ 0.005)\n",
    "print(\"got to this point\")\n",
    "img = noisy(\"gauss\",img,[0,gauss_param])\n",
    "\n",
    "img = img.astype(\"uint8\")\n",
    "io.imsave(filename.replace(\".png\",\"_degraded.png\"),img)\n",
    "print(\"degraded image savded\")\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "!python evaluate.py --root Model_Evaluation_Triplets/Degraded --weights  trained_models/Previous_Models/Network_15.04.2021_20groups_10blocks --imageSize 260 --out Model_Evaluation_Triplets/Processed  --model rcan --nch_in 3 --nch_out 3 --n_resgroups 20  --n_resblocks 10 --workers 0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run.py --root trainingdata/testpartitioned_128 --out trained_models/ERNet_rcan-rg5-t --imageSize 128 --model rcan --nch_in 3 --nch_out 3 --ntrain 1500 --ntest 100 --batchSize 3 --n_resgroups 20 --n_resblocks 10 --lr 0.0001 --scheduler 20,0.5  --plotinterval 33 --dataset pickledataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py --root Model_Evaluation_Input/Processed_Input_B --weights trained_models/ERNet_rcan-rg5-t/ --imageSize 800   --out Model_Evaluation_Output/ --model rcan --nch_in 3 --nch_out 3 --n_resgroups 20  --n_resblocks 10 "
   ]
  },
  {
   "source": [
    "# Generate Bovey Training Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "rootdir = \"trainingdata/testBovey1024/oosker\"\n",
    "files = [x[2] for x in os.walk(rootdir)]\n",
    "print(files[0])\n",
    "files = files[0]\n",
    "for i in range(0,len(files)):\n",
    "    file_name = rootdir + \"/\" + files[i]\n",
    "    file_name2 = file_name.replace(\"oosker\",\"oosker_greyscale/\")\n",
    "    file_name3 = file_name2.replace(\".png\",\"_greyscale.png\")\n",
    "    image = Image.open(file_name)\n",
    "    image = np.array(image)\n",
    "    image = np.mean(image, axis=2)\n",
    "    image = image.astype(np.uint8)\n",
    "    image = Image.fromarray(image)\n",
    "    image.save(file_name3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#subdirs = [x[0] for x in os.walk(rootdir)]\n",
    "#print(subdirs)\n",
    "#for i in range(1,len(subdirs)):\n",
    "#    subdirs2 = [x[2] for x in os.walk(subdirs[i])]\n",
    "#    subdirs2 = subdirs2[0]\n",
    "#    for j in range(0,len(subdirs2)):\n",
    "#        file_name = subdirs[i] +\"/\"+ subdirs2[j]\n",
    "#        file_name2 = subdirs[i] +\"_\"+ subdirs2[j]\n",
    "#        file_name3 = file_name2.replace(\"oosker\",\"oosker_greyscale\")\n",
    "#        image = Image.open(file_name)  \n",
    "#        image.save(file_name3)\n",
    "        \n",
    "#print(subdirs2)\n",
    "#for subdir, dirs, files in os.walk(rootdir): in subdirs\n",
    " #   for subdir in subdirs:\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['20_1-0_testimg.png', '20_5-0_testimg.png', '4_2-0_testimg.png', '20_2-0_testimg.png', '12_6-0_testimg.png', '4_1-0_testimg.png', '20_0-0_testimg.png', '12_2-0_testimg.png', '16_2-0_testimg.png', '16_3-0_testimg.png', '16_1-0_testimg.png', '12_0-0_testimg.png', '12_5-0_testimg.png', '12_4-0_testimg.png', '1_6-0_testimg.png', '16_5-0_testimg.png', '8_4-0_testimg.png', '4_6-0_testimg.png', '8_0-0_testimg.png', '4_5-0_testimg.png', '12_1-0_testimg.png', '1_2-0_testimg.png', '8_6-0_testimg.png', '16_0-0_testimg.png', '4_4-0_testimg.png', '8_2-0_testimg.png', '8_1-0_testimg.png', '12_3-0_testimg.png', '8_3-0_testimg.png', '20_6-0_testimg.png', '16_6-0_testimg.png', '20_4-0_testimg.png', '1_5-0_testimg.png', '16_4-0_testimg.png', '1_4-0_testimg.png', '4_3-0_testimg.png', '1_1-0_testimg.png', '4_0-0_testimg.png', '20_3-0_testimg.png', '8_5-0_testimg.png', '1_3-0_testimg.png', '1_0-0_testimg.png']\n"
     ]
    }
   ]
  },
  {
   "source": [
    "### Oscar 15g5b"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py --root  trainingdata/testBovey1024/oosker   --weights  trained_models/Previous_Models/Network_13_04_2021_15groups_5blocks    --imageSize 260            --out trainingdata/testBovey1024/oosker15g5b   --model rcan --nch_in 3 --nch_out 3 --n_resgroups 15  --n_resblocks 5 --workers 0\n",
    "\n",
    "\n",
    "trainingdata/testBovey1024/oosker"
   ]
  },
  {
   "source": [
    "### Oscar 20g10b"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "!python evaluate.py --root  trainingdata/testBovey1024/oosker   --weights  trained_models/Previous_Models/Network_15_04_2021_20groups_10blocks --imageSize 260             --out trainingdata/testBovey1024/oosker20g10b    --model rcan --nch_in 3 --nch_out 3 --n_resgroups 15  --n_resblocks 5 --workers 0"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### Bovey denoising"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "!python evaluate.py --root  trainingdata/testBovey1024/oosker_greyscale  --weights  trained_models/Previous_Models/Network_Bovey_Widefield_Restoration  --imageSize 270             --out trainingdata/testBovey1024/ooskerBovey    --model rcan --nch_in 1 --nch_out 1 --n_resgroups 18  --n_resblocks 8 --workers 0"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(batchSize=16, batchSize_test=1, cpu=False, dataset='imagedataset', fid=<_io.TextIOWrapper name='trainingdata/testBovey1024/ooskerBovey/log.txt' mode='w' encoding='UTF-8'>, imageSize=270, log=False, lr=0.0001, model='rcan', multigpu=False, n_feats=64, n_resblocks=8, n_resgroups=18, narch=0, nch_in=1, nch_out=1, nepoch=10, ntest=10, ntrain=0, out='trainingdata/testBovey1024/ooskerBovey', plotinterval=1, reduction=16, root='trainingdata/testBovey1024/oosker_greyscale', saveinterval=10, scheduler='', test=False, testinterval=1, undomulti=False, weights='trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/final.pth', workers=0)\n",
      "loading checkpoint trained_models/Previous_Models/Network_Bovey_Widefield_Restoration/final.pth\n",
      "0.0 0.9607843137254902 (512, 512)\n",
      "[4/4][1/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/16_0-0_testimg_greyscale.png 0\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][2/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/12_1-0_testimg_greyscale.png 1\n",
      "saved\n",
      "0.0 0.8823529411764706 (512, 512)\n",
      "[4/4][3/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/12_0-0_testimg_greyscale.png 2\n",
      "saved\n",
      "0.011764705882352941 0.9607843137254902 (512, 512)\n",
      "[4/4][4/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/1_6-0_testimg_greyscale.png 3\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][5/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/8_5-0_testimg_greyscale.png 4\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][6/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/16_2-0_testimg_greyscale.png 5\n",
      "saved\n",
      "0.0 0.9137254901960784 (512, 512)\n",
      "[4/4][7/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/8_4-0_testimg_greyscale.png 6\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][8/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/16_6-0_testimg_greyscale.png 7\n",
      "saved\n",
      "0.0 0.8117647058823529 (512, 512)\n",
      "[4/4][9/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/12_3-0_testimg_greyscale.png 8\n",
      "saved\n",
      "0.0 0.8901960784313725 (512, 512)\n",
      "[4/4][10/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/16_3-0_testimg_greyscale.png 9\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][11/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/12_5-0_testimg_greyscale.png 10\n",
      "saved\n",
      "0.0 0.9411764705882353 (512, 512)\n",
      "[4/4][12/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/16_4-0_testimg_greyscale.png 11\n",
      "saved\n",
      "0.0 0.9411764705882353 (512, 512)\n",
      "[4/4][13/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/20_0-0_testimg_greyscale.png 12\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][14/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/20_2-0_testimg_greyscale.png 13\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][15/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/16_1-0_testimg_greyscale.png 14\n",
      "saved\n",
      "0.0 0.792156862745098 (512, 512)\n",
      "[4/4][16/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/1_4-0_testimg_greyscale.png 15\n",
      "saved\n",
      "0.0 0.8549019607843137 (512, 512)\n",
      "[4/4][17/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/1_5-0_testimg_greyscale.png 16\n",
      "saved\n",
      "0.0 0.6392156862745098 (512, 512)\n",
      "[4/4][18/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/4_3-0_testimg_greyscale.png 17\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][19/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/8_1-0_testimg_greyscale.png 18\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][20/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/20_4-0_testimg_greyscale.png 19\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][21/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/8_2-0_testimg_greyscale.png 20\n",
      "saved\n",
      "0.0 0.7803921568627451 (512, 512)\n",
      "[4/4][22/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/4_0-0_testimg_greyscale.png 21\n",
      "saved\n",
      "0.0 0.9450980392156862 (512, 512)\n",
      "[4/4][23/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/20_3-0_testimg_greyscale.png 22\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][24/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/20_5-0_testimg_greyscale.png 23\n",
      "saved\n",
      "0.0 0.47843137254901963 (512, 512)\n",
      "[4/4][25/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/1_3-0_testimg_greyscale.png 24\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][26/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/20_6-0_testimg_greyscale.png 25\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][27/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/20_1-0_testimg_greyscale.png 26\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][28/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/16_5-0_testimg_greyscale.png 27\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][29/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/8_6-0_testimg_greyscale.png 28\n",
      "saved\n",
      "0.0 0.8862745098039215 (512, 512)\n",
      "[4/4][30/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/4_4-0_testimg_greyscale.png 29\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][31/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/4_1-0_testimg_greyscale.png 30\n",
      "saved\n",
      "0.0 0.6745098039215687 (512, 512)\n",
      "[4/4][32/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/1_0-0_testimg_greyscale.png 31\n",
      "saved\n",
      "0.0 0.7450980392156863 (512, 512)\n",
      "[4/4][33/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/8_3-0_testimg_greyscale.png 32\n",
      "saved\n",
      "0.00392156862745098 1.0 (512, 512)\n",
      "[4/4][34/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/1_1-0_testimg_greyscale.png 33\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][35/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/4_6-0_testimg_greyscale.png 34\n",
      "saved\n",
      "0.0 0.9725490196078431 (512, 512)\n",
      "[4/4][36/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/4_5-0_testimg_greyscale.png 35\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][37/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/12_2-0_testimg_greyscale.png 36\n",
      "saved\n",
      "0.0 0.9529411764705882 (512, 512)\n",
      "[4/4][38/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/1_2-0_testimg_greyscale.png 37\n",
      "saved\n",
      "0.0 0.8352941176470589 (512, 512)\n",
      "[4/4][39/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/8_0-0_testimg_greyscale.png 38\n",
      "saved\n",
      "0.0 0.984313725490196 (512, 512)\n",
      "[4/4][40/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/12_4-0_testimg_greyscale.png 39\n",
      "saved\n",
      "0.0 0.996078431372549 (512, 512)\n",
      "[4/4][41/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/4_2-0_testimg_greyscale.png 40\n",
      "saved\n",
      "0.0 1.0 (512, 512)\n",
      "[4/4][42/42], shape is 270x270 - trainingdata/testBovey1024/oosker_greyscale/12_6-0_testimg_greyscale.png 41\n",
      "saved\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "run  ERNet Oscar.ipynb",
   "provenance": [
    {
     "file_id": "1Y7sXcwwn71dGqAPcxQq5BhV-tK5ls1ki",
     "timestamp": 1609165100940
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python376jvsc74a57bd047d517df254fbe59b5c04b69f23871c524fea7fc7dc51e349dcd158d9476f98d",
   "display_name": "Python 3.7.6 64-bit ('pytorch_latest_p37': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}